---
permalink: /
title: "About"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


<!-- Hi! I am Chaoda Zheng, a Ph.D. student at the Chinese University of Hong Kong, Shenzhen (CUHKSZ) in the [School of Science and Engineering](https://sse.cuhk.edu.cn/en) and [Future Network of Intelligence Institute (FNII)](https://fnii.cuhk.edu.cn/).
I am currently supervised by [Dr. Zhen Li](https://mypage.cuhk.edu.cn/academics/lizhen/) and co-supervised by [Shuguang Cui](https://sse.cuhk.edu.cn/en/faculty/cuishuguang).

My research interests focus on 3D computer vision, including - but not limited to - 3D object detection and tracking, Scene understanding. -->

Hello, I'm Chaoda Zheng, currently pursuing my Ph.D. at the Chinese University of Hong Kong, Shenzhen (CUHKSZ).
I am privileged to conduct my research under the expert supervision of [Dr. Zhen Li](https://mypage.cuhk.edu.cn/academics/lizhen/), and additionally co-supervised by the highly accomplished [Prof. Shuguang Cui](https://sse.cuhk.edu.cn/en/faculty/cuishuguang).
My academic journey is guided by my passion for 3D computer vision, with a specific focus on perception tasks related to Autonomous Driving and Indoor Scene Understanding. However, I don't limit myself to these areas; I am continuously exploring and broadening my knowledge in other related aspects such as neural rendering and multi-modal learning.


# News
**[2023/07]** One paper on 3D point cloud upsampling is accepted by ACM MM 2023.

**[2023/07]** One paper on 3D lane detections is accepted by ICCV 2023.

**[2023/06]** Won **1st** place in 4D Semantic Segmentation and **3rd** place in 4D Action Segmentation at the CVPR 2023's HOI4D Challenge.  

**[2023/01]** [**CAT**](https://ieeexplore.ieee.org/document/10011208) is accepted by TNNLS.  

**[2022/11]** [**PointCMT**](https://github.com/ZhanHeshen/PointCMT) is accepted by NeuraIPS 2022 (**Spotlight**). It can improve arbitrary point-based encoder via cross-modal training.  

**[2022/10]** [**2DPASS**](https://github.com/yanx27/2DPASS) is accepted by ECCV 2022. With cross-modal distillation, our pure point-based network beats multi-modal networks in KITTI and NuScenes.  

**[2022/06]** [**M2-Track**](https://ghostish.github.io/MM-Track/) is accepted by CVPR 2022 (**Oral**). The proposed motion-centric paradigm is Faster, Superior, and Memory-Efficient.   

**[2021/10]** Won **2nd** award in ICCV 2021 Challenge on [Urban Scenes Understanding](https://competitions.codalab.org/competitions/31519#learn_the_details).

**[2021/10]** [**BAT**](https://github.com/Ghostish/BAT) is accepted by ICCV 2021. It enhances existing tracker with a simply-yet-effective box-aware feature enhancement.

**[2021/6]** [**CAR-NET**](https://ieeexplore.ieee.org/document/9442303) is accepted by TIP. It ranks 1st on ModelNet40/10 and ShapeNetCore55 benchmarks.

**[2020/6]** Our robust and versatile point cloud operator [**PointASNL**](https://github.com/yanx27/PointASNL) is accepted by CVPR 2020. 

# Activities
### Reviewer
CVPR, ICCV, TIP
### Talks
+ Invited talk at TechBeat on Motion-Centric Single Object Tracking, June 2022. [[Recording]](https://www.techbeat.net/talk-info?id=674)

### Teaching Assistant
+ CUHKSZ CIE6032: Selected Topics in Deep Learning Foundations and Their Applications  
+ CUHKSZ CSC1001: Introduction to Computer Science: Programming Methodology  
+ CUHKSZ CSC4140: Computer Graphics

